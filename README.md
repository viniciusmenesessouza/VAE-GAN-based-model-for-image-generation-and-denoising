# VAE-GAN-based-model-for-image-generation-and-denoising
This practical project aims to develop a deep learning model capable of generating synthetic images and performing image denoising. This practical project aims to develop a deep learning model capable of generating synthetic images and performing image denoising. To achieve this, we propose using a known architecture, which combines the representational strength of a Variational Autoencoder (VAE) with the image generation quality of a Generative Adversarial Network (GAN), called VAE-GAN [1]. The model comprises three key components (see Fig. 1a): (i) an encoder, (ii) a decoder/generator, and (iii) a discriminator. The encoder processes noisy input images and maps them to a meaningful latent representation. The generator then reconstructs images from this latent space. Depending on the input, the latent vector can either be sampled randomly—for synthetic image generation (see Fig. 1b)—or obtained from the encoder to perform image denoising (see Fig. 1c). The discriminator is used during training to distinguish between real and generated images, encouraging the generator to produce realistic outputs

![training_page-0001](https://github.com/user-attachments/assets/634038b2-a30a-4156-8125-25d9efe656e7)

Methodology

To carry out this project, the VAE-GAN model will be implemented using PyTorch [1]. Each component consists of a Convolutional Neural Network, with its configuration adapted to a specific task: upsampling for the decoder/generator, and downsampling for the encoder and discriminator. The GAN loss, L<sub>GAN</sub>, uses binary cross-entropy with respect to the Discriminator/Generator output, while the VAE loss, L<sub>VAE</sub>, includes a log-likelihood term (expressed via the GAN discriminator) and a regularization term based on the Kullback-Leibler divergence (D<sub>KL</sub>). For a data sample x, with latent representation z, the mentioned losses are defined as:
